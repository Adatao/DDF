# make a file appender and a console appender
# Print the date in ISO 8601 format
log4j.appender.myConsoleAppender=org.apache.log4j.ConsoleAppender
log4j.appender.myConsoleAppender.layout=org.apache.log4j.PatternLayout
log4j.appender.myConsoleAppender.layout.ConversionPattern=%d [%t] %-5p %c - %m%n

log4j.appender.myFileAppender=org.apache.log4j.RollingFileAppender
log4j.appender.myFileAppender.File=/tmp/ddf.log
log4j.appender.myFileAppender.layout=org.apache.log4j.PatternLayout
log4j.appender.myFileAppender.layout.ConversionPattern=%d [%t] %-5p %c - %m%n

log4j.appender.ddfFileAppender=org.apache.log4j.RollingFileAppender
log4j.appender.ddfFileAppender.File=/tmp/ddf.short.log
log4j.appender.ddfFileAppender.layout=org.apache.log4j.PatternLayout
log4j.appender.ddfFileAppender.layout.ConversionPattern=%d [%t] %-5p %c - %m%n

# By default, everything goes to console and file
log4j.rootLogger=DEBUG, myFileAppender, myConsoleAppender

# adatao.bigr logger separated to bigr shortlog file
log4j.logger.adatao.ddf=DEBUG, ddfFileAppender

# The noisier spark logs go to file only
log4j.logger.spark.rdd.HadoopRDD=DEBUG, myFileAppender
log4j.additivity.spark.rdd.HadoopRDD=false
log4j.logger.spark.storage=INFO, myFileAppender
log4j.additivity.spark.storage=false
log4j.logger.spark.CacheTracker=INFO, myFileAppender
log4j.additivity.spark.CacheTracker=false
log4j.logger.spark.CacheTrackerActor=INFO, myFileAppender
log4j.additivity.spark.CacheTrackerActor=false
log4j.logger.spark.MapOutputTrackerActor=INFO, myFileAppender
log4j.additivity.spark.MapOutputTrackerActor=false
log4j.logger.spark.MapOutputTracker=INFO, myFileAppender
log4j.additivty.spark.MapOutputTracker=false
log4j.logger.org.apache.hadoop.hive=INFO, myFileAppender
log4j.additivty.org.apache.hadoop.hive=false
log4j.logger.DataNucleus=INFO, myFileAppender
log4j.additivty.DataNucleus=false
